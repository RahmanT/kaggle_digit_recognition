{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # we need it because we will load pixels as well as labels as arraes this array will be passed to our training model\n",
    "import pandas as pd #this library is used to read the training and test data set which is in case two CSV files \n",
    "import matplotlib.pyplot as plt # i have to know my dataset better so this library helps me to visualize it\n",
    "import tensorflow as tf#the mind of my friend\n",
    "from tensorflow import keras#the body of my intelegent friend\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\rahman\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "readtrain = pd.read_csv(\"train.csv\") .as_matrix()#here we read the training data set, its better to have it as a matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_train=readtrain[0:37000,1:] #it will load column 1 to the end for each row in matrix as array, 784 pixel\n",
    "my_label=readtrain[0:37000,0]# the index 0 of this matrix is used to store label of a digit , the label will be 0 to 9\n",
    "\n",
    "test= readtrain[37000:,1:]#from 31000 to 42000\n",
    "test_label=readtrain[37000:,0]#labels from 31000 to 42000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_train = my_train.reshape(-1,28,28)#reshape into 3_dimentional array\n",
    "test=test.reshape(-1,28,28)#the same as abov ;) but for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37000, 28, 28)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_train.shape#is it working well?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_train = tf.keras.utils.normalize(my_train, axis=1)#the numbers are between 255 and 0, but we need 0 to 1 , why?\n",
    "\n",
    "test = tf.keras.utils.normalize(test, axis=1)#he same as abov ;) but for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "37000/37000 [==============================] - 11s 285us/step - loss: 0.3482 - acc: 0.8932\n",
      "Epoch 2/10\n",
      "37000/37000 [==============================] - 10s 261us/step - loss: 0.1258 - acc: 0.9615\n",
      "Epoch 3/10\n",
      "37000/37000 [==============================] - 10s 272us/step - loss: 0.0830 - acc: 0.9743\n",
      "Epoch 4/10\n",
      "37000/37000 [==============================] - 10s 262us/step - loss: 0.0542 - acc: 0.9821\n",
      "Epoch 5/10\n",
      "37000/37000 [==============================] - 10s 262us/step - loss: 0.0443 - acc: 0.9865\n",
      "Epoch 6/10\n",
      "37000/37000 [==============================] - 10s 264us/step - loss: 0.0369 - acc: 0.9878\n",
      "Epoch 7/10\n",
      "37000/37000 [==============================] - 10s 261us/step - loss: 0.0270 - acc: 0.9908\n",
      "Epoch 8/10\n",
      "37000/37000 [==============================] - 10s 275us/step - loss: 0.0274 - acc: 0.9912\n",
      "Epoch 9/10\n",
      "37000/37000 [==============================] - 10s 271us/step - loss: 0.0210 - acc: 0.9933\n",
      "Epoch 10/10\n",
      "37000/37000 [==============================] - 10s 268us/step - loss: 0.0213 - acc: 0.9932\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2a6c37fe470>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the simple model with many usles layer ;)\n",
    "model3 = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(392, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(196, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(98, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(49, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(25, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "#just compile and optimize\n",
    "model3.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "#defining bachsize is somehow tricky smaller bach size make the training longer but more accurate(maybe!) \n",
    "model3.fit(my_train,my_label,batch_size=64, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 1s 172us/step\n",
      "0.12865499990344398\n",
      "0.9714\n"
     ]
    }
   ],
   "source": [
    "#here we can test on a part of dataset which were not envolved in training session\n",
    "val_loss, val_acc = model3.evaluate(test, test_label)\n",
    "print(val_loss)\n",
    "print(val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 28, 28)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"incase of testing in human understandable(what a word!) form, lest see if the prediction is correct in real challenge :D, i have to add an extra dimention \n",
    "to the test set so the model will understand it that way.\n",
    "\"\"\"\n",
    "from numpy import zeros, newaxis\n",
    "b=test[:,newaxis,:,:]\n",
    "b[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the predicted label is :  9\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the currect label is : 9\n"
     ]
    }
   ],
   "source": [
    "#challenge time UUU ha ha ha \n",
    "a=77\n",
    "predictions_single = model3.predict(b[a])\n",
    "#print(predictions_single)\n",
    "prd=np.argmax(predictions_single)\n",
    "print(\"the predicted label is : \",prd)\n",
    "plt.imshow(test[a],cmap=plt.cm.binary)\n",
    "plt.show()\n",
    "print (\"the currect label is :\", test_label[a])\n",
    "#laugh on wate(dont minde its a persian idiom its jus nonesence )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.save('kaggle_digit_recognize3.model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
